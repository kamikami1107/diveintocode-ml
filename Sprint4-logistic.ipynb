{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰スクラッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**雛形**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLogisticRegression():\n",
    "    \"\"\"\n",
    "    ロジスティック回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    x_1 = X\n",
    "    x_theta = np.ones(x_1.shape[0])\n",
    "\n",
    "    h_theta_1 = 1.0 / (1.0 + np.exp(-h_theta))\n",
    "    \n",
    "    return  h_theta_1 \n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使いラベルを推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使い確率を推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】仮定関数\n",
    "\n",
    "ロジスティック回帰の仮定関数のメソッドをScratchLogisticRegressionクラスに実装してください。\n",
    "\n",
    "\n",
    "ロジスティック回帰の仮定関数は、線形回帰の仮定関数を**シグモイド関数**に通したものです。シグモイド関数は以下の式で表されます。\n",
    "\n",
    "$$\n",
    "g(z) = \\frac{1}{1+e^{−z}}.\n",
    "$$\n",
    "\n",
    "線形回帰の仮定関数は次の式でした。\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\theta^T \\cdot x.\n",
    "$$\n",
    "\n",
    "まとめて書くと、ロジスティック回帰の仮定関数は次のようになります。\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\frac{1}{1+e^{−\\theta^T \\cdot x}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰の仮定関数の式をそのまま使えば良さそう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80218588, 0.86063747, 0.90388675, 0.93473206, 0.95615843,\n",
       "       0.97077083, 0.98061168, 0.98718306, 0.99154637])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    h_theta_1 = 1.0 / (1.0 + np.exp(-h_theta))\n",
    "    \n",
    "    return h_theta_1\n",
    "\n",
    "X = np.concatenate([x_theta.reshape(-1, 1), x_1.reshape(-1, 1)], axis=1)\n",
    "theta = np.random.random(len(X[0]))\n",
    "self = 0\n",
    "\n",
    "_linear_hypothesis(self, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#元式\n",
    "x_1 = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "x_theta = np.ones(x_1.shape[0])\n",
    "print(x_1)\n",
    "print(x_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([x_theta.reshape(-1, 1), x_1.reshape(-1, 1)], axis=1)\n",
    "theta = np.random.random(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [1. 4.]\n",
      " [1. 5.]\n",
      " [1. 6.]\n",
      " [1. 7.]\n",
      " [1. 8.]\n",
      " [1. 9.]]\n",
      "(9, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97943035 0.42058218]\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(theta)\n",
    "print(theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.44397077]\n",
      " [1.93483377]\n",
      " [2.42569678]\n",
      " [2.91655979]\n",
      " [3.40742279]\n",
      " [3.8982858 ]\n",
      " [4.38914881]\n",
      " [4.88001182]\n",
      " [5.37087482]]\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "h_theta = np.dot(X, theta)\n",
    "print(h_theta.reshape(-1, 1))\n",
    "print(h_theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.92874985e-22 2.13159824e-22 2.35578038e-22 2.60353997e-22\n",
      " 2.87735666e-22 3.17997090e-22 3.51441136e-22 3.88402523e-22\n",
      " 4.29251173e-22 4.74395913e-22 5.24288566e-22 5.79428476e-22\n",
      " 6.40367501e-22 7.07715539e-22 7.82146632e-22 8.64405711e-22\n",
      " 9.55316054e-22 1.05578752e-21 1.16682566e-21 1.28954179e-21\n",
      " 1.42516408e-21 1.57504990e-21 1.74069934e-21 1.92377029e-21\n",
      " 2.12609498e-21 2.34969834e-21 2.59681827e-21 2.86992803e-21\n",
      " 3.17176100e-21 3.50533801e-21 3.87399763e-21 4.28142952e-21\n",
      " 4.73171139e-21 5.22934982e-21 5.77932534e-21 6.38714229e-21\n",
      " 7.05888391e-21 7.80127321e-21 8.62174028e-21 9.52849662e-21\n",
      " 1.05306174e-20 1.16381321e-20 1.28621251e-20 1.42148466e-20\n",
      " 1.57098351e-20 1.73620528e-20 1.91880359e-20 2.12060592e-20\n",
      " 2.34363199e-20 2.59011392e-20 2.86251858e-20 3.16357229e-20\n",
      " 3.49628809e-20 3.86399592e-20 4.27037592e-20 4.71949527e-20\n",
      " 5.21584892e-20 5.76440454e-20 6.37065226e-20 7.04065961e-20\n",
      " 7.78113224e-20 8.59948106e-20 9.50389638e-20 1.05034299e-19\n",
      " 1.16080853e-19 1.28289182e-19 1.41781473e-19 1.56692761e-19\n",
      " 1.73172283e-19 1.91384971e-19 2.11513104e-19 2.33758131e-19\n",
      " 2.58342688e-19 2.85512826e-19 3.15540472e-19 3.48726153e-19\n",
      " 3.85402003e-19 4.25935085e-19 4.70731069e-19 5.20238288e-19\n",
      " 5.74952226e-19 6.35420480e-19 7.02248235e-19 7.76104327e-19\n",
      " 8.57727931e-19 9.47935965e-19 1.04763126e-18 1.15781160e-18\n",
      " 1.27957971e-18 1.41415428e-18 1.56288219e-18 1.72725194e-18\n",
      " 1.90890862e-18 2.10967029e-18 2.33154625e-18 2.57675711e-18\n",
      " 2.84775702e-18 3.14725824e-18 3.47825828e-18 3.84406990e-18\n",
      " 4.24835426e-18 4.69515757e-18 5.18895161e-18 5.73467841e-18\n",
      " 6.33779980e-18 7.00435203e-18 7.74100616e-18 8.55513488e-18\n",
      " 9.45488627e-18 1.04492653e-17 1.15482242e-17 1.27627615e-17\n",
      " 1.41050329e-17 1.55884721e-17 1.72279260e-17 1.90398028e-17\n",
      " 2.10422364e-17 2.32552677e-17 2.57010455e-17 2.84040481e-17\n",
      " 3.13913279e-17 3.46927827e-17 3.83414545e-17 4.23738605e-17\n",
      " 4.68303583e-17 5.17555501e-17 5.71987288e-17 6.32143716e-17\n",
      " 6.98626851e-17 7.72102078e-17 8.53304763e-17 9.43047608e-17\n",
      " 1.04222879e-16 1.15184095e-16 1.27298112e-16 1.40686171e-16\n",
      " 1.55482265e-16 1.71834478e-16 1.89906467e-16 2.09879105e-16\n",
      " 2.31952283e-16 2.56346918e-16 2.83307158e-16 3.13102832e-16\n",
      " 3.46032144e-16 3.82424663e-16 4.22644616e-16 4.67094538e-16\n",
      " 5.16219299e-16 5.70510557e-16 6.30511676e-16 6.96823168e-16\n",
      " 7.70108700e-16 8.51101739e-16 9.40612890e-16 1.03953801e-15\n",
      " 1.14886718e-15 1.26969459e-15 1.40322954e-15 1.55080848e-15\n",
      " 1.71390843e-15 1.89416175e-15 2.09337249e-15 2.31353439e-15\n",
      " 2.55685093e-15 2.82575729e-15 3.12294478e-15 3.45138774e-15\n",
      " 3.81437336e-15 4.21553451e-15 4.65888615e-15 5.14886548e-15\n",
      " 5.69037639e-15 6.28883850e-15 6.95024141e-15 7.68120469e-15\n",
      " 8.48904403e-15 9.38184459e-15 1.03685418e-14 1.14590109e-14\n",
      " 1.26641655e-14 1.39960675e-14 1.54680467e-14 1.70948354e-14\n",
      " 1.88927149e-14 2.08796791e-14 2.30756141e-14 2.55024977e-14\n",
      " 2.81846188e-14 3.11488210e-14 3.44247711e-14 3.80452559e-14\n",
      " 4.20465104e-14 4.64685804e-14 5.13557237e-14 5.67568523e-14\n",
      " 6.27260226e-14 6.93229760e-14 7.66137370e-14 8.46712741e-14\n",
      " 9.35762297e-14 1.03417728e-13 1.14294265e-13 1.26314698e-13\n",
      " 1.39599331e-13 1.54281120e-13 1.70507007e-13 1.88439386e-13\n",
      " 2.08257729e-13 2.30160386e-13 2.54366565e-13 2.81118530e-13\n",
      " 3.10684024e-13 3.43358948e-13 3.79470324e-13 4.19379566e-13\n",
      " 4.63486100e-13 5.12231358e-13 5.66103201e-13 6.25640794e-13\n",
      " 6.91440011e-13 7.64159391e-13 8.44526736e-13 9.33346388e-13\n",
      " 1.03150728e-12 1.13999185e-12 1.25988584e-12 1.39238919e-12\n",
      " 1.53882804e-12 1.70066800e-12 1.87952882e-12 2.07720059e-12\n",
      " 2.29566168e-12 2.53709853e-12 2.80392751e-12 3.09881914e-12\n",
      " 3.42472479e-12 3.78490624e-12 4.18296831e-12 4.62289492e-12\n",
      " 5.10908903e-12 5.64641661e-12 6.24025543e-12 6.89654882e-12\n",
      " 7.62186519e-12 8.42346375e-12 9.30936717e-12 1.02884419e-11\n",
      " 1.13704867e-11 1.25663313e-11 1.38879439e-11 1.53485517e-11\n",
      " 1.69627729e-11 1.87467633e-11 2.07183777e-11 2.28973485e-11\n",
      " 2.53054836e-11 2.79668846e-11 3.09081875e-11 3.41588299e-11\n",
      " 3.77513454e-11 4.17216891e-11 4.61095974e-11 5.09589861e-11\n",
      " 5.63183895e-11 6.22414462e-11 6.87874363e-11 7.60218741e-11\n",
      " 8.40171644e-11 9.28533267e-11 1.02618796e-10 1.13411309e-10\n",
      " 1.25338881e-10 1.38520886e-10 1.53089255e-10 1.69189792e-10\n",
      " 1.86983638e-10 2.06648879e-10 2.28382331e-10 2.52401511e-10\n",
      " 2.78946809e-10 3.08283901e-10 3.40706402e-10 3.76538807e-10\n",
      " 4.16139739e-10 4.59905538e-10 5.08274225e-10 5.61729892e-10\n",
      " 6.20807541e-10 6.86098439e-10 7.58256042e-10 8.38002526e-10\n",
      " 9.26136021e-10 1.02353860e-09 1.13118509e-09 1.25015286e-09\n",
      " 1.38163259e-09 1.52694016e-09 1.68752985e-09 1.86500892e-09\n",
      " 2.06115362e-09 2.27792704e-09 2.51749871e-09 2.78226636e-09\n",
      " 3.07487987e-09 3.39826781e-09 3.75566675e-09 4.15065367e-09\n",
      " 4.58718173e-09 5.06961984e-09 5.60279641e-09 6.19204764e-09\n",
      " 6.84327098e-09 7.56298406e-09 8.35839003e-09 9.23744958e-09\n",
      " 1.02089606e-08 1.12826464e-08 1.24692526e-08 1.37806554e-08\n",
      " 1.52299795e-08 1.68317304e-08 1.86019389e-08 2.05583219e-08\n",
      " 2.27204594e-08 2.51099909e-08 2.77508317e-08 3.06694120e-08\n",
      " 3.38949421e-08 3.74597042e-08 4.13993755e-08 4.57533856e-08\n",
      " 5.05653109e-08 5.58833108e-08 6.17606095e-08 6.82560291e-08\n",
      " 7.54345778e-08 8.33681009e-08 9.21359999e-08 1.01826027e-07\n",
      " 1.12535162e-07 1.24370587e-07 1.37450754e-07 1.51906574e-07\n",
      " 1.67882725e-07 1.85539102e-07 2.05052416e-07 2.26617961e-07\n",
      " 2.50451575e-07 2.76791789e-07 3.05902227e-07 3.38074234e-07\n",
      " 3.73629798e-07 4.12924771e-07 4.56352429e-07 5.04347408e-07\n",
      " 5.57390059e-07 6.16011247e-07 6.80797671e-07 7.52397733e-07\n",
      " 8.31528028e-07 9.18980513e-07 1.01563044e-06 1.12244511e-06\n",
      " 1.24049354e-06 1.37095721e-06 1.51514182e-06 1.67449041e-06\n",
      " 1.85059777e-06 2.04522644e-06 2.26032430e-06 2.49804409e-06\n",
      " 2.76076495e-06 3.05111625e-06 3.37200386e-06 3.72663928e-06\n",
      " 4.11857174e-06 4.55172374e-06 5.03043030e-06 5.55948233e-06\n",
      " 6.14417460e-06 6.79035870e-06 7.50450160e-06 8.29375037e-06\n",
      " 9.16600372e-06 1.01299910e-05 1.11953595e-05 1.23727712e-05\n",
      " 1.36740091e-05 1.51120954e-05 1.67014218e-05 1.84578933e-05\n",
      " 2.03990873e-05 2.25444297e-05 2.49153889e-05 2.75356911e-05\n",
      " 3.04315569e-05 3.36319640e-05 3.71689371e-05 4.10778678e-05\n",
      " 4.53978687e-05 5.01721647e-05 5.54485247e-05 6.12797396e-05\n",
      " 6.77241496e-05 7.48462275e-05 8.27172229e-05 9.14158739e-05\n",
      " 1.01029194e-04 1.11653341e-04 1.23394576e-04 1.36370327e-04\n",
      " 1.50710358e-04 1.66558065e-04 1.84071905e-04 2.03426978e-04\n",
      " 2.24816770e-04 2.48455082e-04 2.74578156e-04 3.03447030e-04\n",
      " 3.35350130e-04 3.70606141e-04 4.09567165e-04 4.52622223e-04\n",
      " 5.00201107e-04 5.52778637e-04 6.10879359e-04 6.75082731e-04\n",
      " 7.46028834e-04 8.24424686e-04 9.11051194e-04 1.00677082e-03\n",
      " 1.11253603e-03 1.22939862e-03 1.35851995e-03 1.50118226e-03\n",
      " 1.65880108e-03 1.83293894e-03 2.02532039e-03 2.23784852e-03\n",
      " 2.47262316e-03 2.73196076e-03 3.01841632e-03 3.33480731e-03\n",
      " 3.68423990e-03 4.07013772e-03 4.49627316e-03 4.96680165e-03\n",
      " 5.48629890e-03 6.05980149e-03 6.69285092e-03 7.39154134e-03\n",
      " 8.16257115e-03 9.01329865e-03 9.95180187e-03 1.09869426e-02\n",
      " 1.21284350e-02 1.33869178e-02 1.47740317e-02 1.63024994e-02\n",
      " 1.79862100e-02 1.98403057e-02 2.18812709e-02 2.41270214e-02\n",
      " 2.65969936e-02 2.93122308e-02 3.22954647e-02 3.55711893e-02\n",
      " 3.91657228e-02 4.31072549e-02 4.74258732e-02 5.21535631e-02\n",
      " 5.73241759e-02 6.29733561e-02 6.91384203e-02 7.58581800e-02\n",
      " 8.31726965e-02 9.11229610e-02 9.97504891e-02 1.09096821e-01\n",
      " 1.19202922e-01 1.30108474e-01 1.41851065e-01 1.54465265e-01\n",
      " 1.67981615e-01 1.82425524e-01 1.97816111e-01 2.14165017e-01\n",
      " 2.31475217e-01 2.49739894e-01 2.68941421e-01 2.89050497e-01\n",
      " 3.10025519e-01 3.31812228e-01 3.54343694e-01 3.77540669e-01\n",
      " 4.01312340e-01 4.25557483e-01 4.50166003e-01 4.75020813e-01\n",
      " 5.00000000e-01 5.24979187e-01 5.49833997e-01 5.74442517e-01\n",
      " 5.98687660e-01 6.22459331e-01 6.45656306e-01 6.68187772e-01\n",
      " 6.89974481e-01 7.10949503e-01 7.31058579e-01 7.50260106e-01\n",
      " 7.68524783e-01 7.85834983e-01 8.02183889e-01 8.17574476e-01\n",
      " 8.32018385e-01 8.45534735e-01 8.58148935e-01 8.69891526e-01\n",
      " 8.80797078e-01 8.90903179e-01 9.00249511e-01 9.08877039e-01\n",
      " 9.16827304e-01 9.24141820e-01 9.30861580e-01 9.37026644e-01\n",
      " 9.42675824e-01 9.47846437e-01 9.52574127e-01 9.56892745e-01\n",
      " 9.60834277e-01 9.64428811e-01 9.67704535e-01 9.70687769e-01\n",
      " 9.73403006e-01 9.75872979e-01 9.78118729e-01 9.80159694e-01\n",
      " 9.82013790e-01 9.83697501e-01 9.85225968e-01 9.86613082e-01\n",
      " 9.87871565e-01 9.89013057e-01 9.90048198e-01 9.90986701e-01\n",
      " 9.91837429e-01 9.92608459e-01 9.93307149e-01 9.93940199e-01\n",
      " 9.94513701e-01 9.95033198e-01 9.95503727e-01 9.95929862e-01\n",
      " 9.96315760e-01 9.96665193e-01 9.96981584e-01 9.97268039e-01\n",
      " 9.97527377e-01 9.97762151e-01 9.97974680e-01 9.98167061e-01\n",
      " 9.98341199e-01 9.98498818e-01 9.98641480e-01 9.98770601e-01\n",
      " 9.98887464e-01 9.98993229e-01 9.99088949e-01 9.99175575e-01\n",
      " 9.99253971e-01 9.99324917e-01 9.99389121e-01 9.99447221e-01\n",
      " 9.99499799e-01 9.99547378e-01 9.99590433e-01 9.99629394e-01\n",
      " 9.99664650e-01 9.99696553e-01 9.99725422e-01 9.99751545e-01\n",
      " 9.99775183e-01 9.99796573e-01 9.99815928e-01 9.99833442e-01\n",
      " 9.99849290e-01 9.99863630e-01 9.99876605e-01 9.99888347e-01\n",
      " 9.99898971e-01 9.99908584e-01 9.99917283e-01 9.99925154e-01\n",
      " 9.99932276e-01 9.99938720e-01 9.99944551e-01 9.99949828e-01\n",
      " 9.99954602e-01 9.99958922e-01 9.99962831e-01 9.99966368e-01\n",
      " 9.99969568e-01 9.99972464e-01 9.99975085e-01 9.99977456e-01\n",
      " 9.99979601e-01 9.99981542e-01 9.99983299e-01 9.99984888e-01\n",
      " 9.99986326e-01 9.99987627e-01 9.99988805e-01 9.99989870e-01\n",
      " 9.99990834e-01 9.99991706e-01 9.99992495e-01 9.99993210e-01\n",
      " 9.99993856e-01 9.99994441e-01 9.99994970e-01 9.99995448e-01\n",
      " 9.99995881e-01 9.99996273e-01 9.99996628e-01 9.99996949e-01\n",
      " 9.99997239e-01 9.99997502e-01 9.99997740e-01 9.99997955e-01\n",
      " 9.99998149e-01 9.99998326e-01 9.99998485e-01 9.99998629e-01\n",
      " 9.99998760e-01 9.99998878e-01 9.99998984e-01 9.99999081e-01\n",
      " 9.99999168e-01 9.99999248e-01 9.99999319e-01 9.99999384e-01\n",
      " 9.99999443e-01 9.99999496e-01 9.99999544e-01 9.99999587e-01\n",
      " 9.99999626e-01 9.99999662e-01 9.99999694e-01 9.99999723e-01\n",
      " 9.99999750e-01 9.99999773e-01 9.99999795e-01 9.99999814e-01\n",
      " 9.99999832e-01 9.99999848e-01 9.99999863e-01 9.99999876e-01\n",
      " 9.99999887e-01 9.99999898e-01 9.99999908e-01 9.99999917e-01\n",
      " 9.99999925e-01 9.99999932e-01 9.99999938e-01 9.99999944e-01\n",
      " 9.99999949e-01 9.99999954e-01 9.99999959e-01 9.99999963e-01\n",
      " 9.99999966e-01 9.99999969e-01 9.99999972e-01 9.99999975e-01\n",
      " 9.99999977e-01 9.99999979e-01 9.99999981e-01 9.99999983e-01\n",
      " 9.99999985e-01 9.99999986e-01 9.99999988e-01 9.99999989e-01\n",
      " 9.99999990e-01 9.99999991e-01 9.99999992e-01 9.99999992e-01\n",
      " 9.99999993e-01 9.99999994e-01 9.99999994e-01 9.99999995e-01\n",
      " 9.99999995e-01 9.99999996e-01 9.99999996e-01 9.99999997e-01\n",
      " 9.99999997e-01 9.99999997e-01 9.99999997e-01 9.99999998e-01\n",
      " 9.99999998e-01 9.99999998e-01 9.99999998e-01 9.99999998e-01\n",
      " 9.99999999e-01 9.99999999e-01 9.99999999e-01 9.99999999e-01\n",
      " 9.99999999e-01 9.99999999e-01 9.99999999e-01 9.99999999e-01\n",
      " 9.99999999e-01 9.99999999e-01 9.99999999e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#h_theta_exp = 1 / 1+((h_theta)/e)\n",
    "h_theta_1 = 1.0 / (1.0 + np.exp(-h_theta))\n",
    "print(h_theta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_theta = np.arange(-50, 50, 0.1)\n",
    "h_theta_1 = 1.0 / (1.0 + np.exp(-h_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#計算式本当に合ってる？\n",
    "plt.title(\"gradient1\", size=20, weight='heavy')\n",
    "plt.xlabel(\"h_theta_1\", size=18)\n",
    "plt.ylabel(\"h_theta\", size=18)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.plot(h_theta, h_theta_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】最急降下法\n",
    "\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにしてください。\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m}  \\sum_{i=1}^{m}(h_θ(x^{(i)}) − y^{(i)})x_j^{(i)}  ,j = 0\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\biggl(\\frac{1}{m}  \\sum_{i=1}^{m}(h_θ(x^{(i)}) − y^{(i)})x_j^{(i)} \\biggr) + \\frac{λ}{m}\\theta_j　 ,j\\geq 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰のスクラッチで用いた式が使えそうなので、それを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6468814bef77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#j=0の時は正則化項は足さない\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_1\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#j=0の時は正則化項を足す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mramuda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_1\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#元式\n",
    "\n",
    "y = np.array([1, 3, 5, 7, 9, 11, 13, 15, 17])\n",
    "y_1 = _linear_hypothesis(self, X)\n",
    "\n",
    "alph = 0.01\n",
    "\n",
    "#error = (y_1- y)\n",
    "#error_1 =  np.dot((y_1- y), X)#(9,)と(9,2)の計算なので転置\n",
    "#error_2 = np.mean([np.dot((y_1- y), X)], axis=0)\n",
    "#error_3 = alpha*np.mean([np.dot((y_1- y), X)], axis=0)\n",
    "ramuda = 1\n",
    "\n",
    "#j=0の時は正則化項は足さない\n",
    "gradient[0] = alpha*np.mean([np.dot((y_1- y), X)], axis=0)\n",
    "#j=0の時は正則化項を足す\n",
    "gradient[1] = np.mean(ramuda*theta) + alpha*np.mean([np.dot((y_1- y), X)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
