{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abst\n",
    "\n",
    "最新の物体検出ネットワークは，物体の位置を仮説化するために領域提案アルゴリズムに依存している．\n",
    "<span style=\"color: red; \">SPPnet [1]やFast R-CNN [2]などの進歩により，これらの検出ネットワークの実行時間が短縮された．</span>\n",
    "提案計算がボトルネックとなっている．**本研究では，全画像を共有する領域提案ネットワーク(RPN)を導入する．**\n",
    "畳み込み特徴量を検出ネットワークと組み合わせることで，ほぼコストのかからない領域提案が可能になります．<span style=\"color: red; \">RPNは，完全な畳み込み\n",
    "ネットワークは，各位置での物体境界と物体性スコアを同時に予測します．</span>エンドツーエンドで以下のように学習されるRPNは，高速R-CNNの検出に利用される．\n",
    "<span style=\"color: blue; \">さらに我々はRPNとFast R-CNNの畳み込み特徴を共有することで、単一のネットワーク内で合併させ、\"注意すべき\"メカニズムを用いたニューラルネットワークの最近よく使われる用語を用いて言えば、RPNコンポーネントが統一されたネットワークのどこを見るべきかを伝えてくれる。</span>\n",
    "非常に深いVGG-16モデルについては[3]、当社の検出システムは、GPU上で5fps（全ステップを含む）のフレームレートを実現しながら、最先端の物体検出を実現しています。\n",
    "PASCAL VOC 2007, 2012, および MS COCO のデータセットでは，1 画像あたり 300 件のプロポーザルのみで精度が向上しています。\n",
    "ILSVRCとCOCO2015年大会、Faster R-CNNとRPNは、複数のトラックで1位入賞の基礎となっています。コード公開されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "最近の物体検出の進歩は領域提案法の成功例(例: [4] )と地域ベースの畳み込みニューラルネットワーク（RCNN）[5]である。領域ベースCNNは[5]で開発された当初は計算量が高かったが，提案間で畳み込みを共有することでコストが大幅に削減された[1], [2]．最新のFast R-CNN [2]は，領域提案に費やされた時間を無視して，非常に深いネットワークを用いてリアルタイムに近いレートを達成している[3]．今、提案するのは、最先端の検出システムにおけるテスト時間計算のボトルネックである。\n",
    "\n",
    "領域提案法は、一般的に安価な特徴量と経済的な推論スキームに依存している。\n",
    "最も一般的な手法の1つである選択的探索[4]は、設計された低レベルの特徴に基づいてスーパーピクセルを貪欲にマージします。\n",
    "しかし、効率的な検出ネットワーク[2]と比較すると、選択的探索は、CPU実装では画像1枚あたり2秒と、桁違いに遅くなります。\n",
    "EdgeBoxes [6] は、現在のところ、提案の品質と速度の間の最良のトレードオフを提供しており、1画像あたり0.2秒です。\n",
    "それにもかかわらず、領域 提案ステップはまだ同じくらいの実行時間を消費します を検出ネットワークとして使用します。\n",
    "***\n",
    "我々の観測では、高速RCNNのような領域ベースの検出器で使用される畳み込み特徴量マップは、領域提案の生成にも使用できることがわかった。\n",
    "これらの畳み込み特徴量の上に，我々は畳み込み層をいくつか追加してRPNを構築し，規則的なグリッド上の各場所の領域境界と物体性スコアを同時に回帰させる．\n",
    "したがって，RPN は完全畳み込みネットワーク (FCN) [7] の一種であり，検出提案を生成するためのタスクのためにエンドツーエンドで特別に訓練することができる．\n",
    "RPNは、幅広いスケールとアスペクト比の領域提案を効率的に予測するように設計されています。画像のピラミッド(図1, a)やフィルタのピラミッド(図1, b)を用いる一般的な手法 [8], [9], [1], [2] とは対照的に，我々は複数の縮尺やアスペクト比で参照として機能する新しい「アンカー」ボックスを導入する．\n",
    "我々のスキームは、複数のスケールやアスペクト比の画像やフィルタを列挙する必要がなく、回帰参照のピラミッドと考えることができます（図1、c）。\n",
    "このモデルは、シングルスケールの画像を使って学習してテストしたときにうまく動作するので、実行速度が向上します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchors\n",
    "\n",
    "各スライドウィンドウ位置において、同時に複数の領域提案を予測し、ここで、各位置に対する最大可能な提案の数をｋと表記する。\n",
    "したがって、reg層はk個のボックスの座標を符号化した4k個の出力を持ち、cls層は各提案4に対してオブジェクトかオブジェクトでないかの確率を推定する2k個のスコアを出力します。\n",
    "k個の提案は、我々がアンカーと呼ぶk個の参照ボックスに対して相対的にパラメータ化されています。\n",
    "アンカーは、問題のスライドウィンドウの中心にあり、スケールとアスペクト比に関連付けられています（図3、左）。\n",
    "デフォルトでは、3つのスケールと3つのアスペクト比を使用しており、各スライド位置でk = 9個のアンカーが得られます。\n",
    "サイズW × H (一般的には約2400)の畳み込み特徴量マップでは、合計でW Hkのアンカーがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "効率的かつ正確な領域提案生成のためのRPNを提示した。\n",
    "畳み込み特徴量をダウンストリーム検出ネットワークと共有することで、領域提案ステップはほぼコストフリーである。\n",
    "我々の手法により、深層学習に基づいた統一的な物体検出システムをほぼリアルタイムのフレームレートで実行することが可能となる。\n",
    "また，学習されたRPNは領域提案の品質を向上させ，全体的な物体検出精度を向上させる．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Image from Gyazo](https://i.gyazo.com/1af63513bf833339bcc0d51e064a3581.png)](https://gyazo.com/1af63513bf833339bcc0d51e064a3581)\n",
    "図1：複数のスケールとサイズに対応するためのさまざまなスキーム (a) \n",
    "画像と特徴量マップのピラミッドを構築し，すべてのスケールで分類器を実行する．(b) \n",
    "複数のスケール/サイズを持つフィルタのピラミッドを特徴量マップ上で実行しています。(c) \n",
    "回帰関数では、参照箱のピラミッドを使っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Image from Gyazo](https://i.gyazo.com/eb7418ce389f528eb303ebe32953ea65.png)](https://gyazo.com/eb7418ce389f528eb303ebe32953ea65)\n",
    "\n",
    "図2：Faster R-CNN は、物体検出のための単一の統一されたネットワークです。\n",
    "RPN モジュールは、この統一されたネットワークの「注意」として機能します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Image from Gyazo](https://i.gyazo.com/cd77e6132dc89e71ee80c84b94ce929a.png)](https://gyazo.com/cd77e6132dc89e71ee80c84b94ce929a)\n",
    "\n",
    "図3：\n",
    "\n",
    "左： Region Proposal Network （RPN）。\n",
    "\n",
    "\n",
    "右：PASCAL上でのRPNを用いた検出例。PASCAL VOC 2007テストにおけるRPNによる検出例。私たちの手法は、様々なスケールやアスペクト比の物体を検出することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Image from Gyazo](https://i.gyazo.com/dacb36017ad9812c8c812e8e31390d24.png)](https://gyazo.com/dacb36017ad9812c8c812e8e31390d24)\n",
    "\n",
    "図4：PASCAL VOC 2007のテストセットにおけるリコールとIoUの重複率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Image from Gyazo](https://i.gyazo.com/377e6a267b547e09c01176af8dc4eef3.jpg)](https://gyazo.com/377e6a267b547e09c01176af8dc4eef3)\n",
    "\n",
    "図5: Faster R-CNNシステムを用いたPASCAL VOC 2007テストセットでの物体検出結果の選択例。\n",
    "モデルはVGG-16、学習データは07+12 trainval（2007年のテストセットの73.2%のmAP）である。\n",
    "我々の手法では，様々なスケールとアスペクト比の物体を検出しています．\n",
    "各出力ボックスにはカテゴリラベルとソフトマックススコアが[0, 1]で与えられます。\n",
    "スコアのしきい値0.6がこれらの画像を表示するために使用されます。\n",
    "これらの結果を得るための実行時間は，すべてのステップを含めて，1画像あたり198msです．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからが解答です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 物体検出の分野にはどういった手法が存在したか。\n",
    "\n",
    "1.  SPPnet や Fast R-CNN\n",
    "\n",
    "【該当箇所】\n",
    "**Abst：**\n",
    "<span style=\"color: red; \">Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks.</span>\n",
    "\n",
    "2. region proposal methods と  region-based convolutional neural networks (RCNNs)\n",
    "\n",
    "【該当箇所】\n",
    "**Intro：**\n",
    "<span style=\"color: red; \">Intro：Recent advances in object detection are driven by　the success of region proposal methods (e.g., [4])　and region-based convolutional neural networks (RCNNs) [5].</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Fasterとあるが、どういった仕組みで高速化したのか。\n",
    "\n",
    "我々の物体検出システムは、Faster R-CNNと呼ばれ、2つのモジュールで構成されている。\n",
    "1つ目のモジュールは、領域を提案する深層完全畳み込みネットワークであり、2つ目のモジュールは、提案された領域を利用するFast R-CNN検出器[2]である。\n",
    "システム全体は、物体検出のための単一の統一されたネットワークである（図2）。\n",
    "\n",
    "【該当箇所】\n",
    "**FASTER R-CNN：**\n",
    "<span style=\"color: red; \">Our object detection system, called Faster R-CNN, is　composed of two modules. \n",
    "The first module is a deep　fully convolutional network that proposes regions,\n",
    "and the second module is the Fast R-CNN detector [2]　that uses the proposed regions. \n",
    "The entire system is a　single, unified network for object detection (Figure 2).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。\n",
    "\n",
    "どちらの手法もスライディングウィンドウを用いているが，領域提案は高速RCNNの第1段階に過ぎず，下流の高速R-CNN検出器が提案に注意を払い，提案を洗練させる．\n",
    "第2段階のカスケードでは，領域の特徴をより忠実にカバーする提案ボックスから，領域ごとの特徴を適応的にプールしている [1], [2]．\n",
    "これにより，より精度の高い検出が可能になると考えています．\n",
    "\n",
    "\n",
    "【該当箇所】\n",
    "**EXPERIMENTS；One-Stage Detection vs. Two-Stage Proposal + Detection：**\n",
    "<span style=\"color: red; \">Though both methods use sliding windows, the　region proposal task is only the first stage of Faster RCNN—the downstream Fast R-CNN detector attends　to the proposals to refine them.\n",
    "In the second stage of　our cascade, the region-wise features are adaptively　pooled [1], [2] from proposal boxes that more faithfully cover the features of the regions.\n",
    "We believe　these features lead to more accurate detections.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) RPNとは何か。\n",
    "1. RPNは，完全な畳み込み ネットワークは，各位置での物体境界と物体性スコアを同時に予測します．エンドツーエンドで以下のように学習されるRPNは，高速R-CNNの検出に利用される．\n",
    "\n",
    "2. RPN は完全畳み込みネットワーク (FCN) [7] の一種であり，検出提案を生成するためのタスクのためにエンドツーエンドで特別に訓練することができます。RPNは、幅広いスケールとアスペクト比の領域提案を効率的に予測するように設計されています。画像のピラミッド(図1, a)やフィルタのピラミッド(図1, b)を用いる一般的な手法 [8], [9], [1], [2]がある。\n",
    "\n",
    "【該当個所】\n",
    "1. **Abst：**\n",
    "<span style=\"color: red; \">An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection.</span>\n",
    "\n",
    "2. **Intro：**\n",
    "<span style=\"color: red; \">The RPN is thus a kind of fully convolutional network (FCN) [7] and can be trained end-toend specifically for the task for generating detection proposals.\n",
    "    RPNs are designed to efficiently predict region proposals with a wide range of scales and aspect ratios. \n",
    "In contrast to prevalent methods [8], [9], [1], [2] that use pyramids of images (Figure 1, a) or pyramids of filters(Figure 1, b),</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) RoIプーリングとは何か。\n",
    "『SPPのピラミッド構造を取り除いたシンプルな幅可変poolingができる。』\n",
    "『ある程度畳み込み処理を行ったfeature mapから、region proposalにあたる部分領域をうまく「固定サイズのfeature map」として抽出したもの。』\n",
    "\n",
    "【該当箇所】\n",
    "\n",
    "本文中にはないのでreferrenceから引っ張りました。\n",
    "\n",
    "参考文献：\n",
    "[1]K. He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling in deep convolutional networks for visual recognition,” in European Conference on Computer Vision (ECCV), 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Anchorのサイズはどうするのが適切か。\n",
    "\n",
    "デフォルトでは、3つのスケールと3つのアスペクト比を使用しています（表8では69.9%のmAP）。\n",
    "\n",
    "【該当個所】\n",
    "**EXPERIMENTS；Sensitivities to Hyper-parameters：**\n",
    "<span style=\"color: red; \"> By default we use\n",
    "3 scales and 3 aspect ratios (69.9% mAP in Table 8).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。\n",
    "\n",
    "用いたデータセット→PASCAL VOC 2007 test set, MS COCO\n",
    "\n",
    "【該当箇所】\n",
    "[![Image from Gyazo](https://i.gyazo.com/4a8a811eb6fbbe052ae0353d8bdfaecb.png)](https://gyazo.com/4a8a811eb6fbbe052ae0353d8bdfaecb)\n",
    "\n",
    "\n",
    "[![Image from Gyazo](https://i.gyazo.com/3979e4155db1797f5d564dd81f6ad931.png)](https://gyazo.com/3979e4155db1797f5d564dd81f6ad931)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表11からも見られるように先行研究に比べてmAPの値が良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8) （アドバンス課題）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask R-CNNではFaster R-CNNが先行研究として比較されている。\n",
    "\n",
    "ちなみにMask R-CNNはFaster R-CNNのCNNの機能の上に全結合ネットワークが追加され、マスク（セグメント化出力）が生成される。\n",
    "\n",
    "参考文献：Kaiming He, Georgia Gkioxari, Piotr Dollar, Ross Girshick, “Mask R-CNN,” 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用したREFERENCES\n",
    "\n",
    "1. K. He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling in deep convolutional networks for visual recognition,” in European Conference on Computer Vision (ECCV), 2014.\n",
    "\n",
    "2. R. Girshick, “Fast R-CNN,” in IEEE International Conference on Computer Vision (ICCV), 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
